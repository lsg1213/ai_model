{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, librosa, glob, pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "class arg():\n",
    "    gpus = '3'\n",
    "    feature = 'mel'\n",
    "    lr = 0.005\n",
    "    decay = 0.98\n",
    "    epoch = 300\n",
    "    batch = 8\n",
    "    channel = 2\n",
    "config = arg()\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.gpus\n",
    "strategy = tf.distribute.MirroredStrategy() # devices)\n",
    "path = './Music/6genres-100s'\n",
    "datapath, label = [], []\n",
    "classes = []\n",
    "sr = 22050\n",
    "with open('Music/6genres-100s/allgenres.mf') as f:\n",
    "    for i in f.readlines()[1:]:\n",
    "        tmp = i.split()\n",
    "        classes.append(tmp[1])\n",
    "        datapath.append(path + tmp[0][:-1])\n",
    "    label = classes\n",
    "    classes = list(set(classes))\n",
    "for i, j in enumerate(label):\n",
    "    label[i] = classes.index(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    raw = []\n",
    "    for i,j in enumerate(datapath):\n",
    "        _raw = librosa.load(j)\n",
    "        if sr != _raw[1]:\n",
    "            print(i, _raw[1])\n",
    "        raw.append(_raw[0][:660000])\n",
    "    return raw\n",
    "\n",
    "def preprocessing(rawdata, label, feature=config.feature):\n",
    "    x_index = 0\n",
    "    val_index = 0\n",
    "    data,val,y,val_y = [],[],[],[]\n",
    "    data = np.zeros((480,128,1290,3))\n",
    "    val = np.zeros((120,128,1290,3))\n",
    "    y = np.zeros((480,len(classes)))\n",
    "    val_y = np.zeros((120,len(classes)))\n",
    "    for i, raw in enumerate(tqdm(rawdata)):\n",
    "        _data = None\n",
    "        if feature == 'mel':\n",
    "#             gen = librosa.feature.melspectrogram(raw)\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(raw)\n",
    "            S_harmonic = librosa.feature.melspectrogram(y_harmonic)\n",
    "            S_percussive = librosa.feature.melspectrogram(y_percussive)\n",
    "#             log_o = librosa.power_to_db(gen, ref=np.max)\n",
    "#             log_Sh = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "#             log_Sp = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "#             _data = np.concatenate([np.expand_dims(log_o,-1),np.expand_dims(log_Sh,-1),np.expand_dims(log_Sp,-1)],axis=-1)\n",
    "            log_Sh = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "            log_Sp = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "            _data = np.concatenate([np.expand_dims(log_Sh,-1),np.expand_dims(log_Sp,-1)],axis=-1)\n",
    "        elif feature == 'stft':\n",
    "            data.append(np.expand_dims(librosa.stft(raw), -1))\n",
    "        elif feature == 'mfcc':\n",
    "            data.append(np.expand_dims(librosa.feature.mfcc(raw), -1))\n",
    "        \n",
    "        if i % 100 < 80:\n",
    "            data[x_index] = _data\n",
    "            y[x_index] = tf.one_hot(label[i], len(classes)).numpy()\n",
    "            x_index += 1\n",
    "        else:\n",
    "            val[val_index] = _data\n",
    "            val_y[val_index] = tf.one_hot(label[i], len(classes)).numpy()\n",
    "            val_index += 1\n",
    "    return (data, val, y, val_y)\n",
    "raw = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [24:38<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "x_2, x_val_2, _, _ = preprocessing(raw, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(x_2,open(datapath + '/x_mel_2.pickle','wb'))\n",
    "# pickle.dump(x_val_2,open(datapath + '/val_x_mel_2.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/root/class'\n",
    "if config.channel == 2:\n",
    "    x= pickle.load(open(datapath + '/x_mel_2.pickle','rb'))\n",
    "    val_x= pickle.load(open(datapath + '/val_x_mel_2.pickle', 'rb'))\n",
    "elif config.channel == 3:\n",
    "    x= pickle.load(open(datapath + '/x_mel.pickle','rb'))\n",
    "    val_x= pickle.load(open(datapath + '/val_x_mel.pickle', 'rb'))\n",
    "y= pickle.load(open(datapath + '/y.pickle', 'rb'))\n",
    "val_y= pickle.load(open(datapath + '/val_y.pickle', 'rb'))\n",
    "assert (len(y) == len(x)) and (len(val_x) == len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(len(x)).batch(config.batch).prefetch(AUTOTUNE)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).shuffle(len(val_x)).batch(config.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (x[0].shape[0], x[0].shape[1], x[0].shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(inputs):\n",
    "    x_1 = BatchNormalization()(inputs)\n",
    "    x_1 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_1)\n",
    "    \n",
    "    x_2 = BatchNormalization()(inputs)\n",
    "    x_2 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_2)\n",
    "    x_2 = BatchNormalization()(x_2)\n",
    "    x_2 = Conv2D(32,(3,3),strides=1,padding='same', activation='relu')(x_2)\n",
    "    \n",
    "    x_3 = BatchNormalization()(inputs)\n",
    "    x_3 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_3)\n",
    "    x_3 = BatchNormalization()(x_3)\n",
    "    x_3 = Conv2D(32,(5,5),strides=1,padding='same', activation='relu')(x_3)\n",
    "    \n",
    "    x_4 = MaxPool2D((3,3), strides=1, padding='same')(inputs)\n",
    "    x_4 = BatchNormalization()(x_4)\n",
    "    x_4 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_4)\n",
    "    \n",
    "    x_5 = BatchNormalization()(inputs)\n",
    "    x_5 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_5)\n",
    "    x_5 = BatchNormalization()(x_5)\n",
    "    x_5 = Conv2D(32,(7,7),strides=1,padding='same', activation='relu')(x_5)\n",
    "    \n",
    "    x_6 = AveragePooling2D((3,3), strides=1, padding='same')(inputs)\n",
    "    x_6 = BatchNormalization()(x_6)\n",
    "    x_6 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_6)\n",
    "    \n",
    "    return Concatenate()([inputs,x_1,x_2,x_3,x_4,x_5,x_6])\n",
    "\n",
    "def build_model():\n",
    "    model_input = Input(shape=shape) # shape 으로 변경\n",
    "    x = tf.transpose(model_input, [0,2,1,3])\n",
    "    x = Conv2D(32,(3,3),strides=1,padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D((4,1))(x)\n",
    "    \n",
    "#     x_1 = inception_block(x)\n",
    "#     x_2 = inception_block(Concatenate()([x,x_1]))\n",
    "#     x_3 = inception_block(Concatenate()([x,x_1,x_2]))\n",
    "    x_1 = inception_block(x)\n",
    "    x_2 = inception_block(x_1)\n",
    "    x_3 = inception_block(x_2)\n",
    "    \n",
    "    x = BatchNormalization()(x_3)\n",
    "    x = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x)\n",
    "    x = AveragePooling2D((2,2), strides=2)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(len(classes), activation='softmax')(x)\n",
    "    return Model(inputs=model_input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model()\n",
    "# model.summary()\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#                                         config.lr,\n",
    "#                                         decay_steps=config.epoch,\n",
    "#                                         decay_rate=config.decay,\n",
    "#                                         staircase=True)\n",
    "factor = 0.7\n",
    "learning_rate = 0.01\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=factor, patience=3, verbose=0, mode='auto',\n",
    ")\n",
    "optimizers = Adam(learning_rate=learning_rate)\n",
    "# optimizers = SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(optimizer=optimizers,\n",
    "                      loss=tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics=['acc', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model_checkpoint/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=0, save_weights_only=True,\n",
    "    # 다섯 번째 에포크마다 가중치를 저장합니다\n",
    "    save_freq='epoch',\n",
    "#     save_best_only=True)\n",
    ")\n",
    "callbacks = [\n",
    "    cp_callback,\n",
    "    lr,\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          patience=25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 60 steps, validate for 15 steps\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 44s 734ms/step - loss: 1.2464 - acc: 0.5104 - Precision: 0.6965 - Recall: 0.2917 - val_loss: 99.1229 - val_acc: 0.1667 - val_Precision: 0.1667 - val_Recall: 0.1667\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 31s 518ms/step - loss: 1.0335 - acc: 0.6021 - Precision: 0.7100 - Recall: 0.3979 - val_loss: 2.5087 - val_acc: 0.4083 - val_Precision: 0.4875 - val_Recall: 0.3250\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 30s 504ms/step - loss: 0.9841 - acc: 0.6250 - Precision: 0.7153 - Recall: 0.4396 - val_loss: 4.6557 - val_acc: 0.2917 - val_Precision: 0.3017 - val_Recall: 0.2917\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 31s 514ms/step - loss: 0.9149 - acc: 0.6562 - Precision: 0.7500 - Recall: 0.4875 - val_loss: 15.4442 - val_acc: 0.1750 - val_Precision: 0.1765 - val_Recall: 0.1750\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 29s 482ms/step - loss: 0.8560 - acc: 0.6854 - Precision: 0.7551 - Recall: 0.5396 - val_loss: 11.3112 - val_acc: 0.1667 - val_Precision: 0.1667 - val_Recall: 0.1667\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 27s 454ms/step - loss: 0.7502 - acc: 0.6938 - Precision: 0.7911 - Recall: 0.5917 - val_loss: 3.1424 - val_acc: 0.3083 - val_Precision: 0.3009 - val_Recall: 0.2833\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 28s 464ms/step - loss: 0.6553 - acc: 0.7646 - Precision: 0.8218 - Recall: 0.6917 - val_loss: 9.2075 - val_acc: 0.1250 - val_Precision: 0.1250 - val_Recall: 0.1250\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 28s 468ms/step - loss: 0.6553 - acc: 0.7604 - Precision: 0.8119 - Recall: 0.6833 - val_loss: 7.8675 - val_acc: 0.1917 - val_Precision: 0.1917 - val_Recall: 0.1917\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 27s 448ms/step - loss: 0.6236 - acc: 0.7937 - Precision: 0.8405 - Recall: 0.6917 - val_loss: 1.8218 - val_acc: 0.4917 - val_Precision: 0.5046 - val_Recall: 0.4583\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 29s 478ms/step - loss: 0.5165 - acc: 0.8250 - Precision: 0.8528 - Recall: 0.7604 - val_loss: 9.9946 - val_acc: 0.1833 - val_Precision: 0.1765 - val_Recall: 0.1750\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 29s 483ms/step - loss: 0.5391 - acc: 0.7854 - Precision: 0.8341 - Recall: 0.7437 - val_loss: 1.8048 - val_acc: 0.4500 - val_Precision: 0.4679 - val_Recall: 0.4250\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 27s 445ms/step - loss: 0.4629 - acc: 0.8229 - Precision: 0.8604 - Recall: 0.7833 - val_loss: 5.5604 - val_acc: 0.3333 - val_Precision: 0.3362 - val_Recall: 0.3250\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.5274 - acc: 0.8021 - Precision: 0.8345 - Recall: 0.7563 - val_loss: 6.5601 - val_acc: 0.3417 - val_Precision: 0.3565 - val_Recall: 0.3417\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 29s 475ms/step - loss: 0.4588 - acc: 0.8375 - Precision: 0.8632 - Recall: 0.8021 - val_loss: 35.6248 - val_acc: 0.2583 - val_Precision: 0.2583 - val_Recall: 0.2583\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 28s 459ms/step - loss: 0.5219 - acc: 0.8062 - Precision: 0.8518 - Recall: 0.7542 - val_loss: 1.9729 - val_acc: 0.5167 - val_Precision: 0.5273 - val_Recall: 0.4833\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 27s 444ms/step - loss: 0.4162 - acc: 0.8375 - Precision: 0.8641 - Recall: 0.8083 - val_loss: 6.1545 - val_acc: 0.3500 - val_Precision: 0.3559 - val_Recall: 0.3500\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 28s 468ms/step - loss: 0.4881 - acc: 0.8354 - Precision: 0.8667 - Recall: 0.7854 - val_loss: 2.9968 - val_acc: 0.4167 - val_Precision: 0.4237 - val_Recall: 0.4167\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 27s 445ms/step - loss: 0.4009 - acc: 0.8562 - Precision: 0.8747 - Recall: 0.8146 - val_loss: 6.0924 - val_acc: 0.3333 - val_Precision: 0.3276 - val_Recall: 0.3167\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 26s 439ms/step - loss: 0.4013 - acc: 0.8646 - Precision: 0.8821 - Recall: 0.8417 - val_loss: 0.7797 - val_acc: 0.7583 - val_Precision: 0.7672 - val_Recall: 0.7417\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 26s 430ms/step - loss: 0.3808 - acc: 0.8687 - Precision: 0.8973 - Recall: 0.8375 - val_loss: 3.9786 - val_acc: 0.3833 - val_Precision: 0.3879 - val_Recall: 0.3750\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 27s 451ms/step - loss: 0.3859 - acc: 0.8771 - Precision: 0.9022 - Recall: 0.8458 - val_loss: 0.7934 - val_acc: 0.7417 - val_Precision: 0.7798 - val_Recall: 0.7083\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 27s 448ms/step - loss: 0.4134 - acc: 0.8542 - Precision: 0.8871 - Recall: 0.8188 - val_loss: 1.1061 - val_acc: 0.6417 - val_Precision: 0.6729 - val_Recall: 0.6000\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 29s 478ms/step - loss: 0.3607 - acc: 0.8562 - Precision: 0.8758 - Recall: 0.8229 - val_loss: 0.7137 - val_acc: 0.7167 - val_Precision: 0.7345 - val_Recall: 0.6917\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 28s 459ms/step - loss: 0.3459 - acc: 0.8750 - Precision: 0.9129 - Recall: 0.8521 - val_loss: 0.7938 - val_acc: 0.7167 - val_Precision: 0.7917 - val_Recall: 0.6333\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 27s 453ms/step - loss: 0.3468 - acc: 0.8854 - Precision: 0.9115 - Recall: 0.8583 - val_loss: 0.6887 - val_acc: 0.7833 - val_Precision: 0.7963 - val_Recall: 0.7167\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 27s 457ms/step - loss: 0.3609 - acc: 0.8500 - Precision: 0.8956 - Recall: 0.8396 - val_loss: 0.4644 - val_acc: 0.8167 - val_Precision: 0.8319 - val_Recall: 0.7833\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 28s 472ms/step - loss: 0.3063 - acc: 0.8958 - Precision: 0.9136 - Recall: 0.8813 - val_loss: 0.5671 - val_acc: 0.8333 - val_Precision: 0.8421 - val_Recall: 0.8000\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 27s 450ms/step - loss: 0.2905 - acc: 0.9062 - Precision: 0.9236 - Recall: 0.8813 - val_loss: 0.8262 - val_acc: 0.7500 - val_Precision: 0.7857 - val_Recall: 0.7333\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 27s 452ms/step - loss: 0.2972 - acc: 0.9062 - Precision: 0.9266 - Recall: 0.8938 - val_loss: 0.2761 - val_acc: 0.9250 - val_Precision: 0.9391 - val_Recall: 0.9000\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 28s 464ms/step - loss: 0.3401 - acc: 0.8833 - Precision: 0.9051 - Recall: 0.8542 - val_loss: 0.2927 - val_acc: 0.9083 - val_Precision: 0.9381 - val_Recall: 0.8833\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 26s 440ms/step - loss: 0.3638 - acc: 0.8687 - Precision: 0.8947 - Recall: 0.8500 - val_loss: 0.6309 - val_acc: 0.7583 - val_Precision: 0.8073 - val_Recall: 0.7333\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 27s 443ms/step - loss: 0.3274 - acc: 0.8813 - Precision: 0.8985 - Recall: 0.8479 - val_loss: 1.6805 - val_acc: 0.4917 - val_Precision: 0.5225 - val_Recall: 0.4833\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 28s 465ms/step - loss: 0.2595 - acc: 0.9062 - Precision: 0.9190 - Recall: 0.8750 - val_loss: 0.5539 - val_acc: 0.8083 - val_Precision: 0.8407 - val_Recall: 0.7917\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 26s 441ms/step - loss: 0.2436 - acc: 0.9104 - Precision: 0.9227 - Recall: 0.8958 - val_loss: 0.3529 - val_acc: 0.8833 - val_Precision: 0.9115 - val_Recall: 0.8583\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 27s 455ms/step - loss: 0.2804 - acc: 0.9062 - Precision: 0.9142 - Recall: 0.8875 - val_loss: 0.2755 - val_acc: 0.9083 - val_Precision: 0.9474 - val_Recall: 0.9000\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 27s 456ms/step - loss: 0.2669 - acc: 0.9021 - Precision: 0.9234 - Recall: 0.8792 - val_loss: 0.5751 - val_acc: 0.8167 - val_Precision: 0.8348 - val_Recall: 0.8000\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 27s 444ms/step - loss: 0.2788 - acc: 0.9062 - Precision: 0.9176 - Recall: 0.8813 - val_loss: 0.2955 - val_acc: 0.9000 - val_Precision: 0.9068 - val_Recall: 0.8917\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.2365 - acc: 0.9208 - Precision: 0.9395 - Recall: 0.9062 - val_loss: 0.5711 - val_acc: 0.7583 - val_Precision: 0.7876 - val_Recall: 0.7417\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 27s 457ms/step - loss: 0.2103 - acc: 0.9479 - Precision: 0.9529 - Recall: 0.9271 - val_loss: 0.3400 - val_acc: 0.9000 - val_Precision: 0.9052 - val_Recall: 0.8750\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 28s 466ms/step - loss: 0.2116 - acc: 0.9187 - Precision: 0.9379 - Recall: 0.9125 - val_loss: 0.3995 - val_acc: 0.8750 - val_Precision: 0.9018 - val_Recall: 0.8417\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1970 - acc: 0.9438 - Precision: 0.9549 - Recall: 0.9271 - val_loss: 0.2823 - val_acc: 0.9250 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 28s 465ms/step - loss: 0.1776 - acc: 0.9458 - Precision: 0.9534 - Recall: 0.9375 - val_loss: 0.3226 - val_acc: 0.8750 - val_Precision: 0.8898 - val_Recall: 0.8750\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 28s 467ms/step - loss: 0.1858 - acc: 0.9438 - Precision: 0.9531 - Recall: 0.9312 - val_loss: 0.4396 - val_acc: 0.8583 - val_Precision: 0.8716 - val_Recall: 0.7917\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 26s 439ms/step - loss: 0.2030 - acc: 0.9333 - Precision: 0.9446 - Recall: 0.9229 - val_loss: 0.3487 - val_acc: 0.9000 - val_Precision: 0.9052 - val_Recall: 0.8750\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 28s 465ms/step - loss: 0.1638 - acc: 0.9500 - Precision: 0.9556 - Recall: 0.9417 - val_loss: 0.3327 - val_acc: 0.9000 - val_Precision: 0.9130 - val_Recall: 0.8750\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 28s 461ms/step - loss: 0.1954 - acc: 0.9396 - Precision: 0.9509 - Recall: 0.9271 - val_loss: 0.2636 - val_acc: 0.9250 - val_Precision: 0.9316 - val_Recall: 0.9083\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 27s 444ms/step - loss: 0.1655 - acc: 0.9479 - Precision: 0.9634 - Recall: 0.9333 - val_loss: 0.3237 - val_acc: 0.9000 - val_Precision: 0.9068 - val_Recall: 0.8917\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 28s 467ms/step - loss: 0.1827 - acc: 0.9500 - Precision: 0.9531 - Recall: 0.9312 - val_loss: 0.3781 - val_acc: 0.8667 - val_Precision: 0.8870 - val_Recall: 0.8500\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 26s 440ms/step - loss: 0.1731 - acc: 0.9542 - Precision: 0.9656 - Recall: 0.9354 - val_loss: 0.3737 - val_acc: 0.8667 - val_Precision: 0.8850 - val_Recall: 0.8333\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 27s 445ms/step - loss: 0.1566 - acc: 0.9604 - Precision: 0.9681 - Recall: 0.9479 - val_loss: 0.3096 - val_acc: 0.8917 - val_Precision: 0.9052 - val_Recall: 0.8750\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1345 - acc: 0.9583 - Precision: 0.9704 - Recall: 0.9563 - val_loss: 0.4274 - val_acc: 0.8250 - val_Precision: 0.8435 - val_Recall: 0.8083\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 27s 458ms/step - loss: 0.1553 - acc: 0.9583 - Precision: 0.9642 - Recall: 0.9542 - val_loss: 0.2724 - val_acc: 0.9250 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.1536 - acc: 0.9542 - Precision: 0.9637 - Recall: 0.9396 - val_loss: 0.3665 - val_acc: 0.8833 - val_Precision: 0.8898 - val_Recall: 0.8750\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 26s 436ms/step - loss: 0.1583 - acc: 0.9542 - Precision: 0.9578 - Recall: 0.9458 - val_loss: 0.3016 - val_acc: 0.8917 - val_Precision: 0.9043 - val_Recall: 0.8667\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1355 - acc: 0.9563 - Precision: 0.9682 - Recall: 0.9500 - val_loss: 0.2319 - val_acc: 0.9417 - val_Precision: 0.9492 - val_Recall: 0.9333\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 27s 448ms/step - loss: 0.1334 - acc: 0.9625 - Precision: 0.9741 - Recall: 0.9417 - val_loss: 0.2481 - val_acc: 0.9167 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 26s 432ms/step - loss: 0.1387 - acc: 0.9625 - Precision: 0.9662 - Recall: 0.9542 - val_loss: 0.2293 - val_acc: 0.9250 - val_Precision: 0.9250 - val_Recall: 0.9250\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 26s 440ms/step - loss: 0.1337 - acc: 0.9646 - Precision: 0.9684 - Recall: 0.9563 - val_loss: 0.3300 - val_acc: 0.8833 - val_Precision: 0.9052 - val_Recall: 0.8750\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 27s 452ms/step - loss: 0.1617 - acc: 0.9500 - Precision: 0.9636 - Recall: 0.9375 - val_loss: 0.2435 - val_acc: 0.9167 - val_Precision: 0.9391 - val_Recall: 0.9000\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 27s 450ms/step - loss: 0.1597 - acc: 0.9479 - Precision: 0.9616 - Recall: 0.9396 - val_loss: 0.3413 - val_acc: 0.8917 - val_Precision: 0.9043 - val_Recall: 0.8667\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 28s 464ms/step - loss: 0.1400 - acc: 0.9521 - Precision: 0.9660 - Recall: 0.9479 - val_loss: 0.2969 - val_acc: 0.9167 - val_Precision: 0.9160 - val_Recall: 0.9083\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 27s 451ms/step - loss: 0.1253 - acc: 0.9708 - Precision: 0.9726 - Recall: 0.9604 - val_loss: 0.3668 - val_acc: 0.8833 - val_Precision: 0.9123 - val_Recall: 0.8667\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 27s 450ms/step - loss: 0.1235 - acc: 0.9729 - Precision: 0.9766 - Recall: 0.9583 - val_loss: 0.2578 - val_acc: 0.9083 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 28s 462ms/step - loss: 0.1300 - acc: 0.9667 - Precision: 0.9746 - Recall: 0.9583 - val_loss: 0.3479 - val_acc: 0.8750 - val_Precision: 0.8938 - val_Recall: 0.8417\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1327 - acc: 0.9708 - Precision: 0.9829 - Recall: 0.9583 - val_loss: 0.2403 - val_acc: 0.9250 - val_Precision: 0.9402 - val_Recall: 0.9167\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 27s 455ms/step - loss: 0.1222 - acc: 0.9729 - Precision: 0.9767 - Recall: 0.9604 - val_loss: 0.2380 - val_acc: 0.9250 - val_Precision: 0.9483 - val_Recall: 0.9167\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 26s 433ms/step - loss: 0.1342 - acc: 0.9646 - Precision: 0.9788 - Recall: 0.9604 - val_loss: 0.2566 - val_acc: 0.9167 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 27s 456ms/step - loss: 0.1134 - acc: 0.9646 - Precision: 0.9726 - Recall: 0.9604 - val_loss: 0.2579 - val_acc: 0.9167 - val_Precision: 0.9298 - val_Recall: 0.8833\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 27s 452ms/step - loss: 0.1404 - acc: 0.9583 - Precision: 0.9660 - Recall: 0.9479 - val_loss: 0.2784 - val_acc: 0.9083 - val_Precision: 0.9130 - val_Recall: 0.8750\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 28s 461ms/step - loss: 0.1112 - acc: 0.9729 - Precision: 0.9788 - Recall: 0.9625 - val_loss: 0.2825 - val_acc: 0.9083 - val_Precision: 0.9130 - val_Recall: 0.8750\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 28s 459ms/step - loss: 0.1052 - acc: 0.9771 - Precision: 0.9789 - Recall: 0.9667 - val_loss: 0.2696 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 28s 472ms/step - loss: 0.1247 - acc: 0.9667 - Precision: 0.9765 - Recall: 0.9521 - val_loss: 0.2490 - val_acc: 0.9250 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1049 - acc: 0.9792 - Precision: 0.9852 - Recall: 0.9729 - val_loss: 0.2623 - val_acc: 0.9083 - val_Precision: 0.9304 - val_Recall: 0.8917\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 27s 456ms/step - loss: 0.1299 - acc: 0.9667 - Precision: 0.9746 - Recall: 0.9583 - val_loss: 0.2554 - val_acc: 0.9167 - val_Precision: 0.9304 - val_Recall: 0.8917\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 27s 455ms/step - loss: 0.1293 - acc: 0.9646 - Precision: 0.9723 - Recall: 0.9521 - val_loss: 0.2599 - val_acc: 0.9167 - val_Precision: 0.9316 - val_Recall: 0.9083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "60/60 [==============================] - 28s 459ms/step - loss: 0.1485 - acc: 0.9583 - Precision: 0.9621 - Recall: 0.9521 - val_loss: 0.2751 - val_acc: 0.9167 - val_Precision: 0.9211 - val_Recall: 0.8750\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 27s 445ms/step - loss: 0.1350 - acc: 0.9604 - Precision: 0.9663 - Recall: 0.9563 - val_loss: 0.2793 - val_acc: 0.9000 - val_Precision: 0.9130 - val_Recall: 0.8750\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.1402 - acc: 0.9625 - Precision: 0.9766 - Recall: 0.9583 - val_loss: 0.2733 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 26s 438ms/step - loss: 0.1235 - acc: 0.9688 - Precision: 0.9788 - Recall: 0.9604 - val_loss: 0.2697 - val_acc: 0.9167 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 26s 437ms/step - loss: 0.1126 - acc: 0.9729 - Precision: 0.9789 - Recall: 0.9688 - val_loss: 0.2552 - val_acc: 0.9167 - val_Precision: 0.9244 - val_Recall: 0.9167\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 27s 449ms/step - loss: 0.0969 - acc: 0.9771 - Precision: 0.9789 - Recall: 0.9688 - val_loss: 0.2528 - val_acc: 0.9167 - val_Precision: 0.9244 - val_Recall: 0.9167\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 26s 439ms/step - loss: 0.1250 - acc: 0.9729 - Precision: 0.9787 - Recall: 0.9583 - val_loss: 0.2498 - val_acc: 0.9167 - val_Precision: 0.9244 - val_Recall: 0.9167\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_dataset,epochs=config.epoch,validation_data=validation_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9411764661518751, epoch: 55\n"
     ]
    }
   ],
   "source": [
    "pre = hist.history['val_Precision']\n",
    "rec = hist.history['val_Recall']\n",
    "f1 = []\n",
    "for i, j in enumerate(pre):\n",
    "    f1.append(2 * pre[i] * rec[i] / (pre[i] + rec[i]))\n",
    "max_epoch = f1.index(np.nanmax(f1))+1\n",
    "print(f'f1_score: {np.nanmax(f1)}, epoch: {max_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82_adam_0.8,0.002,f10.9205021043027561.h5\n",
      "82_adam_0.8,0.004, f10.911392365275926.h5\n",
      "52_adam_0.7,0.001,f10.9367088385641422,channel2.h5\n",
      "79_adam_0.75,0.001,f10.9198312696748169.h5\n",
      "82_adam_0.8,0.004,f10.911392365275926.h5\n",
      "78_adam_0.85,0.002,f10.911392365275926.h5\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir('./기록'):\n",
    "    if i[-3:] == '.h5':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55_adam_0.7,0.01,f10.9411764661518751,channel2\n"
     ]
    }
   ],
   "source": [
    "check_point = f'model_checkpoint/cp-00{max_epoch}.ckpt'\n",
    "model.load_weights(check_point)\n",
    "model.save(f'./기록/{max_epoch}_adam_{factor},{learning_rate},f1{np.max(f1)},channel{config.channel}.h5')\n",
    "print(f'{max_epoch}_adam_{factor},{learning_rate},f1{np.max(f1)},channel{config.channel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '55_adam_0.7,0.01,f10.9411764661518751,channel2' + '.h5'\n",
    "eval_model = tf.keras.models.load_model(f'./기록/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion table\n",
      "[[18.  1.  1.  0.  0.  0.]\n",
      " [ 1. 18.  0.  0.  0.  1.]\n",
      " [ 0.  1. 18.  1.  0.  0.]\n",
      " [ 0.  0.  0. 20.  0.  0.]\n",
      " [ 0.  0.  0.  0. 20.  0.]\n",
      " [ 1.  0.  0.  0.  0. 19.]]\n"
     ]
    }
   ],
   "source": [
    "confusion_table = np.reshape(np.zeros(6*6), (6,6))\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i,j in validation_dataset.unbatch().batch(1):\n",
    "    # j: real, answer: predict\n",
    "    answer = tf.argmax(eval_model.predict(i), axis=-1)\n",
    "    confusion_table[tf.argmax(j, axis=-1)[0]][answer.numpy()[0]] +=  1\n",
    "print('confusion table')\n",
    "print(confusion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is 0.941447779862414\n"
     ]
    }
   ],
   "source": [
    "tp = np.zeros((6))\n",
    "fp = np.zeros_like(tp)\n",
    "fn = np.zeros_like(tp)\n",
    "\n",
    "for i,j in enumerate(confusion_table):\n",
    "    tp[i] = j[i] # confusion table에서 대각선\n",
    "    fn[i] = np.sum(j) - j[i] # confusion table에서 세로축\n",
    "    fp = np.add(fp, j) # confusion table에서 가로축\n",
    "    fp[i] -= j[i]\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(f'f1_score is {np.mean(f1_score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
