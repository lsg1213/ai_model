{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/45\n",
      "2/45\n",
      "3/45\n",
      "4/45\n",
      "5/45\n",
      "6/45\n",
      "7/45\n",
      "8/45\n",
      "9/45\n",
      "10/45\n",
      "11/45\n",
      "12/45\n",
      "13/45\n",
      "14/45\n",
      "15/45\n",
      "16/45\n",
      "17/45\n",
      "18/45\n",
      "19/45\n",
      "20/45\n",
      "21/45\n",
      "22/45\n",
      "23/45\n",
      "24/45\n",
      "25/45\n",
      "26/45\n",
      "27/45\n",
      "28/45\n",
      "29/45\n",
      "30/45\n",
      "31/45\n",
      "32/45\n",
      "33/45\n",
      "34/45\n",
      "35/45\n",
      "36/45\n",
      "37/45\n",
      "38/45\n",
      "39/45\n",
      "40/45\n",
      "41/45\n",
      "42/45\n",
      "43/45\n",
      "44/45\n",
      "45/45\n",
      "data preprocessing complete, data feature is seq\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import librosa\n",
    "# 헬퍼 라이브러리들\n",
    "import numpy as np\n",
    "import os, time\n",
    "from utils import get_data\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "generate_path = './generated_noise/'\n",
    "feature = 'seq'\n",
    "audio_path = '/root/datasets/ai_challenge/NOISEX/all/'\n",
    "resample_sr = 16000\n",
    "length = 4\n",
    "train_data, train_label, label_list = get_data(feature=feature,resample_sr=resample_sr,length=length,audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_data)\n",
    "class_num = len(label_list)\n",
    "batch_size = 32\n",
    "shape = train_data[0].shape\n",
    "if len(shape) == 1:\n",
    "    shape = (shape[0], 1)\n",
    "EPOCHS = 100\n",
    "noise_dim = 30\n",
    "DATA_SHAPE = train_data[0].shape\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label)).shuffle(BUFFER_SIZE).batch(batch_size)\n",
    "\n",
    "def build_generator(output_shape=shape, class_num=class_num, stddev=0.2, z_dim=noise_dim):\n",
    "    noise = Input(shape=(z_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(32, z_dim)(label))\n",
    "\n",
    "    model_input = Concatenate()([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(400, activation='relu')(model_input)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    x = LSTM(10, return_sequences=True)(x)\n",
    "    x = Dense(output_shape[0], activation='tanh')(x)\n",
    "    output = Reshape(output_shape)(x)\n",
    "\n",
    "    return Model([noise, label], output)\n",
    "\n",
    "def build_discriminator(input_shape=shape, class_num=class_num, stddev=0.2):\n",
    "    noise_input = Input(shape=input_shape)\n",
    "    reshaped_noise = Flatten()(noise_input)\n",
    "\n",
    "    noise = Input(shape=input_shape)\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    label_embedding = Flatten()(Embedding(32, np.prod(input_shape))(label))\n",
    "    flat_noise = Flatten()(noise)\n",
    "\n",
    "    x = Concatenate()([flat_noise, label_embedding])\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = LSTM(10)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "\n",
    "    return Model([noise, label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 30)        960         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          24400       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 400)]     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 1, 10)        16440       tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64000)     704000      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64000, 1)     0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 745,800\n",
      "Trainable params: 745,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 64000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64000)     2048000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64000)        0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64000)        0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128000)       0           flatten_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 128000, 1)]  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 10)           480         tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            11          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,048,491\n",
      "Trainable params: 2,048,491\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_generator().summary()\n",
    "build_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1,2,3,4],[5,,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트들을 저장하기 위해서 체크포인트 디렉토리를 생성합니다.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "\n",
    "    # 또는 loss_fn = tf.keras.losses.sparse_categorical_crossentropy를 사용해도 됩니다.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return tf.math.divide_no_nan(tf.math.add(real_loss,fake_loss),2)\n",
    "\n",
    "\n",
    "gen_loss = tf.keras.metrics.Mean(name='gen_loss')\n",
    "dis_loss = tf.keras.metrics.Mean(name='dis_loss')\n",
    "\n",
    "dis_accuracy = tf.keras.metrics.BinaryAccuracy(name='dis_accuracy')\n",
    "\n",
    "# 모델과 옵티마이저는 `strategy.scope`에서 만들어져야 합니다.\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.001, 0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.001, 0.5)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)\n",
    "@tf.function\n",
    "def train_step(noise, label):\n",
    "    random_noise = tf.random.normal([noise.shape[0], noise_dim],dtype=tf.float32)\n",
    "    noise = tf.cast(noise,dtype=tf.float32)\n",
    "    label = tf.expand_dims(label, axis=1)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_noise = generator([random_noise, label], training=True)\n",
    "\n",
    "        real_output = discriminator([noise, label], training=True)\n",
    "        fake_output = discriminator([generated_noise, label], training=True)\n",
    "\n",
    "        g_loss = generator_loss(fake_output)\n",
    "        d_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_loss.update_state(g_loss)\n",
    "        dis_loss.update_state(d_loss)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "    dis_accuracy.update_state(label, tf.math.divide_no_nan(tf.math.add(real_output, fake_output), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 훈련 루프\n",
    "    start = time.time()\n",
    "    g_loss, step = 0., 0\n",
    "    for noise_batch, label_batch in train_dataset:\n",
    "        train_step(noise_batch,label_batch)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "    print (f'{epoch}: d_loss: {dis_loss.result()}, d_accuracy: {dis_accuracy.result()*100}%, g_loss: {gen_loss.result()}',end=', ')\n",
    "    print (f'time: {start - time.time()} seconds')\n",
    "\n",
    "    gen_loss.reset_states()\n",
    "    dis_accuracy.reset_states()\n",
    "    dis_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "#       name='eval_accuracy')\n",
    "\n",
    "# new_model = create_model()\n",
    "# new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "# @tf.function\n",
    "# def eval_step(images, labels):\n",
    "#     predictions = new_model(images, training=False)\n",
    "#     eval_accuracy(labels, predictions)\n",
    "    \n",
    "# checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "# for images, labels in test_dataset:\n",
    "#     eval_step(images, labels)\n",
    "\n",
    "# print ('전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: {}'.format(\n",
    "#     eval_accuracy.result()*100))\n",
    "\n",
    "gen = build_generator()\n",
    "new_optimizer = Adam()\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=new_optimizer, generator=gen)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoin_dir))\n",
    "def sample_noises(generator, epoch):\n",
    "    noise = np.random.normal(0, 1, (class_num,noise_dim))\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1,1)\n",
    "\n",
    "    gen_sound = generator.predict([noise, sampled_labels])\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1)\n",
    "    for i, j in enumerate(sampled_labels):\n",
    "        data = None\n",
    "        if feature == 'stft':\n",
    "            data = librosa.istft(gen_sound[i])\n",
    "        elif feature == 'mfcc':\n",
    "            data = librosa.feature.inverse.mfcc_to_audio(gen_sound[i].T, resample_sr)\n",
    "        elif feature == 'seq':\n",
    "            data = gen_sound[i]\n",
    "        else:\n",
    "            raise ValueError('wrong feature')\n",
    "\n",
    "        librosa.output.write_wav(os.path.join(generate_path, f'{epoch}_{label_list[j]}.wav'), data, resample_sr, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
