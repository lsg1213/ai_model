{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from utils import get_data\n",
    "\n",
    "\n",
    "# 헬퍼 라이브러리들\n",
    "import numpy as np\n",
    "import os, librosa, time\n",
    "import IPython.display as ipd\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/45\n",
      "2/45\n",
      "3/45\n",
      "4/45\n",
      "5/45\n",
      "6/45\n",
      "7/45\n",
      "8/45\n",
      "9/45\n",
      "10/45\n",
      "11/45\n",
      "12/45\n",
      "13/45\n",
      "14/45\n",
      "15/45\n",
      "16/45\n",
      "17/45\n",
      "18/45\n",
      "19/45\n",
      "20/45\n",
      "21/45\n",
      "22/45\n",
      "23/45\n",
      "24/45\n",
      "25/45\n",
      "26/45\n",
      "27/45\n",
      "28/45\n",
      "29/45\n",
      "30/45\n",
      "31/45\n",
      "32/45\n",
      "33/45\n",
      "34/45\n",
      "35/45\n",
      "36/45\n",
      "37/45\n",
      "38/45\n",
      "39/45\n",
      "40/45\n",
      "41/45\n",
      "42/45\n",
      "43/45\n",
      "44/45\n",
      "45/45\n",
      "data preprocessing complete, data feature is seq\n"
     ]
    }
   ],
   "source": [
    "generate_path = './generated_noise/'\n",
    "feature = 'seq'\n",
    "audio_path = '/root/datasets/ai_challenge/NOISEX/all/'\n",
    "resample_sr = 16000\n",
    "length = 4\n",
    "train_data, train_label, label_list = get_data(feature=feature,resample_sr=resample_sr,length=length,audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_data)\n",
    "class_num = len(label_list)\n",
    "batch_size = 8\n",
    "shape = train_data[0].shape\n",
    "EPOCHS = 100\n",
    "noise_dim = 30\n",
    "DATA_SHAPE = train_data[0].shape\n",
    "dis_cell = 0\n",
    "gen_cell = 0\n",
    "if feature == 'seq':\n",
    "    dis_cell = 300\n",
    "    gen_cell = 300\n",
    "elif feature in ('stft', 'mfcc'):\n",
    "    dis_cell = 150\n",
    "    gen_cell = 150\n",
    "else:\n",
    "    raise ValueError('wrong feature')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label)).shuffle(BUFFER_SIZE).batch(batch_size)\n",
    "\n",
    "def build_generator(output_shape=shape, class_num=class_num, stddev=0.2, z_dim=noise_dim):\n",
    "    noise = Input(shape=(z_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(class_num, z_dim)(label))\n",
    "\n",
    "    model_input = Concatenate()([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(400, activation='relu')(model_input)\n",
    "    if tf.rank(x) == 2:\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "    x = LSTM(gen_cell, return_sequences=True)(x)\n",
    "#     x = tf.expand_dims(x, axis=1)\n",
    "    x = LSTM(gen_cell)(x)\n",
    "    \n",
    "    if feature == 'seq':\n",
    "        x = Dense(output_shape[0], activation='tanh')(x)\n",
    "        x = Flatten()(x)\n",
    "        output = Reshape(output_shape)(x)\n",
    "    else:\n",
    "        x = Dense(output_shape[0]*output_shape[1], activation='tanh')(x)\n",
    "        output = Reshape(output_shape)(x)\n",
    "\n",
    "    return Model([noise, label], output)\n",
    "\n",
    "def build_discriminator(input_shape=shape, class_num=class_num, stddev=0.2):\n",
    "    noise_input = Input(shape=input_shape)\n",
    "    reshaped_noise = Flatten()(noise_input)\n",
    "\n",
    "    noise = Input(shape=input_shape)\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    label_embedding = Flatten()(Embedding(class_num, np.prod(input_shape))(label))\n",
    "    flat_noise = Flatten()(noise)\n",
    "\n",
    "    x = Multiply()([flat_noise, label_embedding])\n",
    "    if tf.rank(x) == 2:\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "#     x = tf.transpose(x,[0,2,1])\n",
    "#     x = AveragePooling1D()(x)\n",
    "#     x = LSTM(512, return_sequences=True)(x)\n",
    "    x = LSTM(dis_cell, return_sequences=True)(x)\n",
    "#     if feature == 'seq':\n",
    "#         x = tf.expand_dims(x, axis=1)\n",
    "    x = LSTM(dis_cell, return_sequences=True)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = LSTM(64)(x)\n",
    "#     x = tf.expand_dims(x, axis=1)\n",
    "#     x = LSTM(64)(x)\n",
    "    output = Dense(1)(x)\n",
    "    \n",
    "\n",
    "    return Model([noise, label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트들을 저장하기 위해서 체크포인트 디렉토리를 생성합니다.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "\n",
    "# reduction을 `none`으로 설정합니다. 그래서 우리는 축소를 나중에 하고,\n",
    "# 또는 loss_fn = tf.keras.losses.sparse_categorical_crossentropy를 사용해도 됩니다.\n",
    "gen_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "dis_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return gen_cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    #real_output = (batch, 2)\n",
    "    real_loss = dis_cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = dis_cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return (real_loss + fake_loss) / 2\n",
    "\n",
    "\n",
    "gen_loss = tf.keras.metrics.Mean(name='gen_loss')\n",
    "dis_loss = tf.keras.metrics.Mean(name='dis_loss')\n",
    "\n",
    "dis_accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "  name='dis_accuracy')\n",
    "    \n",
    "# 모델과 옵티마이저는 `strategy.scope`에서 만들어져야 합니다.\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4 * class_num * 10)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "# generator_optimizer = tf.keras.optimizers.SGD(0.03)\n",
    "# discriminator_optimizer = tf.keras.optimizers.SGD(0.03)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)\n",
    "    \n",
    "def train_step(noise, label):\n",
    "    random_noise = tf.random.normal([noise.shape[0], noise_dim],dtype=tf.float32)\n",
    "    noise = tf.cast(noise,dtype=tf.float32)\n",
    "    label = tf.expand_dims(label, axis=-1)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_noise = generator([random_noise, label], training=True)\n",
    "\n",
    "        real_output = discriminator([noise, label], training=True)\n",
    "        fake_output = discriminator([generated_noise, label], training=True)\n",
    "\n",
    "        g_loss = generator_loss(fake_output)\n",
    "        d_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_loss.update_state(g_loss)\n",
    "        dis_loss.update_state(d_loss)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    dis_accuracy.update_state(tf.ones_like(real_output), real_output)\n",
    "    return g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 64000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64000)     960000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64000)        0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64000)        0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64000)        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 64000, 1)]   0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 64000, 300)   362400      tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 64000, 300)   721200      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64000, 1)     301         lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,043,901\n",
      "Trainable params: 2,043,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()\n",
    "# g = build_generator()\n",
    "# d = build_discriminator()\n",
    "# random_noise = tf.random.normal([2, noise_dim],dtype=tf.float32)\n",
    "# s = g([random_noise, tf.expand_dims(tf.constant([[1],[1]]), axis=-1)])\n",
    "# k = d([tf.constant([train_data[0], train_data[1]]), tf.expand_dims(tf.constant([[1],[1]]), axis=-1)], training=False)\n",
    "# b = d([np.expand_dims(s , axis=-1), tf.expand_dims(tf.constant([1]), axis=-1)], training=False)\n",
    "# print(k,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 30)        450         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          24400       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 400)]     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 1, 300)       841200      tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 300)          721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64000)        19264000    lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64000)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64000, 1)     0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,851,250\n",
      "Trainable params: 20,851,250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: d_loss: 4.549447059631348, d_accuracy: 93.43179321289062%, g_loss: 0.04654501751065254, time: 3952.500798225403\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "for epoch in range(EPOCHS):\n",
    "    # 훈련 루프\n",
    "    start = time.time()\n",
    "    g_loss, step = 0., 0\n",
    "    for noise_batch, label_batch in train_dataset:\n",
    "        train_step(noise_batch, label_batch)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "    print (f'{epoch}: d_loss: {dis_loss.result()}, d_accuracy: {dis_accuracy.result()*100}%, g_loss: {gen_loss.result()}, time: {time.time() - start}')\n",
    "\n",
    "\n",
    "    gen_loss.reset_states()\n",
    "    dis_accuracy.reset_states()\n",
    "    dis_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "#       name='eval_accuracy')\n",
    "\n",
    "# new_model = create_model()\n",
    "# new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "# @tf.function\n",
    "# def eval_step(images, labels):\n",
    "#     predictions = new_model(images, training=False)\n",
    "#     eval_accuracy(labels, predictions)\n",
    "    \n",
    "# checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "# for images, labels in test_dataset:\n",
    "#     eval_step(images, labels)\n",
    "\n",
    "# print ('전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: {}'.format(\n",
    "#     eval_accuracy.result()*100))\n",
    "\n",
    "gen = build_generator()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=new_optimizer, generator=gen)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "def sample_noises(generator, epoch):\n",
    "    noise = np.random.normal(0, 1, (class_num,noise_dim))\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1,1)\n",
    "\n",
    "    gen_sound = generator.predict([noise, sampled_labels])\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1)\n",
    "    for i, j in enumerate(sampled_labels):\n",
    "        data = None\n",
    "        if feature == 'stft':\n",
    "            data = librosa.istft(gen_sound[i])\n",
    "        elif feature == 'mfcc':\n",
    "            data = librosa.feature.inverse.mfcc_to_audio(gen_sound[i].T, resample_sr)\n",
    "        elif feature == 'seq':\n",
    "            data = gen_sound[i]\n",
    "        else:\n",
    "            raise ValueError('wrong feature')\n",
    "\n",
    "        librosa.output.write_wav(os.path.join(generate_path, f'{epoch}_{label_list[j]}.wav'), data, resample_sr, norm=True)\n",
    "        print(f'{epoch}_{label_list[j]}.wav')\n",
    "        \n",
    "sample_noises(generator, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(generate_path+'20_destroyerengine.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
