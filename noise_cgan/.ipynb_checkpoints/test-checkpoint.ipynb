{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from utils import get_data\n",
    "\n",
    "\n",
    "# 헬퍼 라이브러리들\n",
    "import numpy as np\n",
    "import os, librosa, time\n",
    "import IPython.display as ipd\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/45\n",
      "2/45\n",
      "3/45\n",
      "4/45\n",
      "5/45\n",
      "6/45\n",
      "7/45\n",
      "8/45\n",
      "9/45\n",
      "10/45\n",
      "11/45\n",
      "12/45\n",
      "13/45\n",
      "14/45\n",
      "15/45\n",
      "16/45\n",
      "17/45\n",
      "18/45\n",
      "19/45\n",
      "20/45\n",
      "21/45\n",
      "22/45\n",
      "23/45\n",
      "24/45\n",
      "25/45\n",
      "26/45\n",
      "27/45\n",
      "28/45\n",
      "29/45\n",
      "30/45\n",
      "31/45\n",
      "32/45\n",
      "33/45\n",
      "34/45\n",
      "35/45\n",
      "36/45\n",
      "37/45\n",
      "38/45\n",
      "39/45\n",
      "40/45\n",
      "41/45\n",
      "42/45\n",
      "43/45\n",
      "44/45\n",
      "45/45\n",
      "data preprocessing complete, data feature is seq\n"
     ]
    }
   ],
   "source": [
    "generate_path = './generated_noise/'\n",
    "feature = 'seq'\n",
    "audio_path = '/root/datasets/ai_challenge/NOISEX/all/'\n",
    "resample_sr = 16000\n",
    "length = 4\n",
    "train_data, train_label, label_list = get_data(feature=feature,resample_sr=resample_sr,length=length,audio_path=audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "GPU number: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print ('GPU number: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_data)\n",
    "class_num = len(label_list)\n",
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "shape = train_data[0].shape\n",
    "EPOCHS = 100\n",
    "noise_dim = 30\n",
    "DATA_SHAPE = train_data[0].shape\n",
    "\n",
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "def build_generator(output_shape=shape, class_num=class_num, stddev=0.2, z_dim=noise_dim):\n",
    "    noise = Input(shape=(z_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(class_num, z_dim)(label))\n",
    "\n",
    "    model_input = Concatenate()([noise, label_embedding])\n",
    "    \n",
    "    x = Dense(400, activation='relu')(model_input)\n",
    "    if tf.rank(x) == 2:\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "    x = LSTM(100, return_sequences=True)(x)\n",
    "    \n",
    "    if feature == 'seq':\n",
    "        x = Dense(output_shape[0], activation='tanh')(x)\n",
    "        x = Flatten()(x)\n",
    "        output = Reshape(output_shape)(x)\n",
    "    else:\n",
    "        x = Dense(output_shape[0]*output_shape[1], activation='tanh')(x)\n",
    "        output = Reshape(output_shape)(x)\n",
    "\n",
    "    return Model([noise, label], output)\n",
    "\n",
    "def build_discriminator(input_shape=shape, class_num=class_num, stddev=0.2):\n",
    "    noise_input = Input(shape=input_shape)\n",
    "    reshaped_noise = Flatten()(noise_input)\n",
    "\n",
    "    noise = Input(shape=input_shape)\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    label_embedding = Flatten()(Embedding(class_num, np.prod(input_shape))(label))\n",
    "    flat_noise = Flatten()(noise)\n",
    "\n",
    "    x = Multiply()([flat_noise, label_embedding])\n",
    "    if tf.rank(x) == 2:\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "#     x = tf.transpose(x,[0,2,1])\n",
    "#     x = AveragePooling1D()(x)\n",
    "#     x = LSTM(512, return_sequences=True)(x)\n",
    "    x = LSTM(100)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = LSTM(64)(x)\n",
    "#     x = tf.expand_dims(x, axis=1)\n",
    "#     x = LSTM(64)(x)\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    return Model([noise, label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트들을 저장하기 위해서 체크포인트 디렉토리를 생성합니다.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "with strategy.scope():\n",
    "    # reduction을 `none`으로 설정합니다. 그래서 우리는 축소를 나중에 하고,\n",
    "    # 또는 loss_fn = tf.keras.losses.sparse_categorical_crossentropy를 사용해도 됩니다.\n",
    "    gen_cross_entropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    dis_cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    def generator_loss(fake_output):\n",
    "        return tf.nn.compute_average_loss(gen_cross_entropy(tf.ones_like(fake_output), fake_output), global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        real_loss = tf.nn.compute_average_loss(dis_cross_entropy(tf.ones_like(real_output), real_output), global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "        fake_loss = tf.nn.compute_average_loss(dis_cross_entropy(tf.zeros_like(fake_output), fake_output), global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "        return tf.math.divide_no_nan(tf.math.add(real_loss,fake_loss),2)\n",
    "\n",
    "with strategy.scope():\n",
    "    gen_loss = tf.keras.metrics.Mean(name='gen_loss')\n",
    "    dis_loss = tf.keras.metrics.Mean(name='dis_loss')\n",
    "\n",
    "    dis_accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "      name='dis_accuracy')\n",
    "    \n",
    "    # 모델과 옵티마이저는 `strategy.scope`에서 만들어져야 합니다.\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "#     generator_optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "#     discriminator_optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    generator_optimizer = tf.keras.optimizers.SGD(0.03)\n",
    "    discriminator_optimizer = tf.keras.optimizers.SGD(0.03)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                    discriminator_optimizer=discriminator_optimizer,\n",
    "                                    generator=generator,\n",
    "                                    discriminator=discriminator)\n",
    "    \n",
    "    def train_step(noise, label):\n",
    "        random_noise = tf.random.normal([noise.shape[0], noise_dim],dtype=tf.float32)\n",
    "        noise = tf.cast(noise,dtype=tf.float32)\n",
    "        label = tf.expand_dims(label, axis=-1)\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_noise = generator([random_noise, label], training=True)\n",
    "\n",
    "            real_output = discriminator([noise, label], training=True)\n",
    "            fake_output = discriminator([generated_noise, label], training=True)\n",
    "\n",
    "            g_loss = generator_loss(fake_output)\n",
    "            d_loss = discriminator_loss(real_output, fake_output)\n",
    "            gen_loss.update_state(g_loss)\n",
    "            dis_loss.update_state(d_loss)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        \n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "        dis_accuracy.update_state(tf.ones_like(real_output), real_output)\n",
    "        dis_accuracy.update_state(tf.zeros_like(fake_output), fake_output)\n",
    "        return g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 64000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64000)     960000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64000)        0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64000)        0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64000)        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 64000, 1)]   0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          40800       tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,000,901\n",
      "Trainable params: 1,000,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()\n",
    "# g = build_generator()\n",
    "# d = build_discriminator()\n",
    "# random_noise = tf.random.normal([1, noise_dim],dtype=tf.float32)\n",
    "# s = g([random_noise, tf.expand_dims(tf.constant([1]), axis=-1)])\n",
    "# k = d([np.expand_dims(train_data[2], axis=0), tf.expand_dims(tf.constant([1]), axis=-1)], training=False)\n",
    "# b = d([np.expand_dims(s , axis=-1), tf.expand_dims(tf.constant([1]), axis=-1)], training=False)\n",
    "# print(k, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 30)        450         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400)          24400       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 1, 400)]     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 1, 100)       200400      tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64000)     6464000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64000)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64000, 1)     0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,689,250\n",
      "Trainable params: 6,689,250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:644: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "0: d_loss: 0.7386635541915894, d_accuracy: 50.0%, g_loss: 0.4671742022037506, time: 416.9544997215271\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "1: d_loss: 0.7313804030418396, d_accuracy: 50.0%, g_loss: 0.47365936636924744, time: 405.95168471336365\n",
      "2: d_loss: 0.6956377625465393, d_accuracy: 50.0%, g_loss: 0.6156754493713379, time: 409.67455554008484\n",
      "3: d_loss: 0.6941492557525635, d_accuracy: 50.0%, g_loss: 0.6349274516105652, time: 403.1055693626404\n",
      "4: d_loss: 0.6930041313171387, d_accuracy: 50.0%, g_loss: 0.6579908728599548, time: 401.7210285663605\n",
      "5: d_loss: 0.6926131248474121, d_accuracy: 50.0%, g_loss: 0.6709476113319397, time: 402.46932554244995\n",
      "6: d_loss: 0.6924836039543152, d_accuracy: 50.0%, g_loss: 0.6777600049972534, time: 404.4807777404785\n",
      "7: d_loss: 0.6924213767051697, d_accuracy: 50.0%, g_loss: 0.682702898979187, time: 402.11643075942993\n",
      "8: d_loss: 0.6923949122428894, d_accuracy: 50.0%, g_loss: 0.6858651041984558, time: 403.1651906967163\n",
      "9: d_loss: 0.6923840641975403, d_accuracy: 50.0%, g_loss: 0.6878530383110046, time: 407.0517547130585\n",
      "10: d_loss: 0.6923803091049194, d_accuracy: 50.0%, g_loss: 0.6886866092681885, time: 411.96040534973145\n",
      "11: d_loss: 0.6923779249191284, d_accuracy: 50.0%, g_loss: 0.6892694234848022, time: 407.9112558364868\n",
      "12: d_loss: 0.6923763155937195, d_accuracy: 50.0%, g_loss: 0.6898678541183472, time: 402.71437549591064\n",
      "13: d_loss: 0.692375898361206, d_accuracy: 50.0%, g_loss: 0.6904110312461853, time: 403.8234407901764\n",
      "14: d_loss: 0.692375123500824, d_accuracy: 50.0%, g_loss: 0.6908063888549805, time: 411.40661907196045\n",
      "15: d_loss: 0.6923741698265076, d_accuracy: 50.0%, g_loss: 0.6910704374313354, time: 405.6757128238678\n",
      "16: d_loss: 0.6923735737800598, d_accuracy: 50.0%, g_loss: 0.6912972331047058, time: 403.5508062839508\n",
      "17: d_loss: 0.6923732161521912, d_accuracy: 50.0%, g_loss: 0.6914759874343872, time: 405.57438611984253\n",
      "18: d_loss: 0.6923732757568359, d_accuracy: 50.0%, g_loss: 0.6915582418441772, time: 402.786283493042\n",
      "19: d_loss: 0.692373514175415, d_accuracy: 50.0%, g_loss: 0.6914706826210022, time: 402.7034227848053\n",
      "20: d_loss: 0.6923733353614807, d_accuracy: 50.0%, g_loss: 0.6916402578353882, time: 404.1657371520996\n",
      "21: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6918109655380249, time: 402.61648392677307\n",
      "22: d_loss: 0.6923731565475464, d_accuracy: 50.0%, g_loss: 0.6919084787368774, time: 404.9929049015045\n",
      "23: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6919730305671692, time: 402.112904548645\n",
      "24: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6920155882835388, time: 405.16573762893677\n",
      "25: d_loss: 0.6923730373382568, d_accuracy: 50.0%, g_loss: 0.6920440793037415, time: 401.31023120880127\n",
      "26: d_loss: 0.6923730373382568, d_accuracy: 50.0%, g_loss: 0.6920562386512756, time: 405.12302565574646\n",
      "27: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6920735239982605, time: 403.1743893623352\n",
      "28: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6921088695526123, time: 404.922158241272\n",
      "29: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.692141056060791, time: 405.4357886314392\n",
      "30: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6921656727790833, time: 402.7380712032318\n",
      "31: d_loss: 0.6923729181289673, d_accuracy: 50.0%, g_loss: 0.692179799079895, time: 401.17346715927124\n",
      "32: d_loss: 0.6923729181289673, d_accuracy: 50.0%, g_loss: 0.6921654939651489, time: 402.79746079444885\n",
      "33: d_loss: 0.6923729181289673, d_accuracy: 50.0%, g_loss: 0.6921684145927429, time: 405.21981620788574\n",
      "34: d_loss: 0.6923729181289673, d_accuracy: 50.0%, g_loss: 0.6921849250793457, time: 403.650719165802\n",
      "35: d_loss: 0.6923728585243225, d_accuracy: 50.0%, g_loss: 0.6921932101249695, time: 400.7119150161743\n",
      "36: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922035813331604, time: 404.8721182346344\n",
      "37: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922122240066528, time: 403.6543219089508\n",
      "38: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922199726104736, time: 404.3337724208832\n",
      "39: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922281980514526, time: 409.8189945220947\n",
      "40: d_loss: 0.6923729181289673, d_accuracy: 50.0%, g_loss: 0.6922364830970764, time: 402.7614469528198\n",
      "41: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922435164451599, time: 404.0110912322998\n",
      "42: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.692249059677124, time: 408.4570484161377\n",
      "43: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922559142112732, time: 404.7936305999756\n",
      "44: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922635436058044, time: 405.2174355983734\n",
      "45: d_loss: 0.6923730373382568, d_accuracy: 50.0%, g_loss: 0.692270040512085, time: 408.6568374633789\n",
      "46: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922704577445984, time: 408.54468393325806\n",
      "47: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922692656517029, time: 407.40094542503357\n",
      "48: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922691464424133, time: 399.2258152961731\n",
      "49: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922728419303894, time: 403.6879725456238\n",
      "50: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922682523727417, time: 402.1032602787018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922746896743774, time: 400.18544840812683\n",
      "52: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922900080680847, time: 401.58367800712585\n",
      "53: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6922978758811951, time: 401.08215737342834\n",
      "54: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923028230667114, time: 402.582328081131\n",
      "55: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923073530197144, time: 402.90542554855347\n",
      "56: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923108696937561, time: 403.05645847320557\n",
      "57: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923145651817322, time: 405.01538467407227\n",
      "58: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923176646232605, time: 401.9892725944519\n",
      "59: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923206448554993, time: 400.9132761955261\n",
      "60: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923223733901978, time: 401.60478377342224\n",
      "61: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923231482505798, time: 404.0876569747925\n",
      "62: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923252940177917, time: 400.20440340042114\n",
      "63: d_loss: 0.6923730373382568, d_accuracy: 50.0%, g_loss: 0.6923254728317261, time: 403.1076898574829\n",
      "64: d_loss: 0.6923730373382568, d_accuracy: 50.0%, g_loss: 0.6923261284828186, time: 402.1841642856598\n",
      "65: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923263072967529, time: 402.54328298568726\n",
      "66: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923264265060425, time: 404.80410718917847\n",
      "67: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923266053199768, time: 402.000581741333\n",
      "68: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923272609710693, time: 401.062486410141\n",
      "69: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923291683197021, time: 402.64564967155457\n",
      "70: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923299431800842, time: 402.87342286109924\n",
      "71: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923321485519409, time: 401.0407176017761\n",
      "72: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923336982727051, time: 401.8568437099457\n",
      "73: d_loss: 0.6923729777336121, d_accuracy: 50.0%, g_loss: 0.6923365592956543, time: 404.04976892471313\n",
      "INFO:tensorflow:Error reported to Coordinator: \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/root/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 165, in _call_for_each_replica\n",
      "    t.has_paused.wait()\n",
      "  File \"/root/anaconda3/envs/ten2.2/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/root/anaconda3/envs/ten2.2/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5bd880efd794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnoise_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5bd880efd794>\u001b[0m in \u001b[0;36mdistributed_train_step\u001b[0;34m(noise_batch, label_batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mper_replica_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_replica_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    949\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m    950\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m--> 951\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2288\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     return _call_for_each_replica(self._container_strategy(), self._devices,\n\u001b[0;32m--> 770\u001b[0;31m                                   fn, args, kwargs)\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m   def _configure(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, devices, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=bare-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, devices, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ten2.2/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # `experimental_run_v2`는 주어진 계산을 복사하고,\n",
    "    # 분산된 입력으로 계산을 수행합니다.\n",
    "        \n",
    "    def distributed_train_step(noise_batch, label_batch):\n",
    "        per_replica_losses = strategy.run(train_step, args=(noise_batch, label_batch))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # 훈련 루프\n",
    "        start = time.time()\n",
    "        g_loss, step = 0., 0\n",
    "        for noise_batch, label_batch in train_dist_dataset:\n",
    "            distributed_train_step(noise_batch, label_batch)\n",
    "            step += 1\n",
    "\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            checkpoint.save(checkpoint_prefix)\n",
    "        print (f'{epoch}: d_loss: {dis_loss.result()}, d_accuracy: {dis_accuracy.result()*100}%, g_loss: {gen_loss.result()}, time: {time.time() - start}')\n",
    "\n",
    "\n",
    "        gen_loss.reset_states()\n",
    "        dis_accuracy.reset_states()\n",
    "        dis_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "#       name='eval_accuracy')\n",
    "\n",
    "# new_model = create_model()\n",
    "# new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "# @tf.function\n",
    "# def eval_step(images, labels):\n",
    "#     predictions = new_model(images, training=False)\n",
    "#     eval_accuracy(labels, predictions)\n",
    "    \n",
    "# checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "# for images, labels in test_dataset:\n",
    "#     eval_step(images, labels)\n",
    "\n",
    "# print ('전략을 사용하지 않고, 저장된 모델을 복원한 후의 정확도: {}'.format(\n",
    "#     eval_accuracy.result()*100))\n",
    "\n",
    "gen = build_generator()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=new_optimizer, generator=gen)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "def sample_noises(generator, epoch):\n",
    "    noise = np.random.normal(0, 1, (class_num,noise_dim))\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1,1)\n",
    "\n",
    "    gen_sound = generator.predict([noise, sampled_labels])\n",
    "    sampled_labels = np.arange(0, class_num).reshape(-1)\n",
    "    for i, j in enumerate(sampled_labels):\n",
    "        data = None\n",
    "        if feature == 'stft':\n",
    "            data = librosa.istft(gen_sound[i])\n",
    "        elif feature == 'mfcc':\n",
    "            data = librosa.feature.inverse.mfcc_to_audio(gen_sound[i].T, resample_sr)\n",
    "        elif feature == 'seq':\n",
    "            data = gen_sound[i]\n",
    "        else:\n",
    "            raise ValueError('wrong feature')\n",
    "\n",
    "        librosa.output.write_wav(os.path.join(generate_path, f'{epoch}_{label_list[j]}.wav'), data, resample_sr, norm=True)\n",
    "        print(f'{epoch}_{label_list[j]}.wav')\n",
    "        \n",
    "sample_noises(generator, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(generate_path+'17_destroyerengine.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
