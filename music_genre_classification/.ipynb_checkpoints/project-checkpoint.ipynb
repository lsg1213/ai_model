{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, librosa, glob, pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "class arg():\n",
    "    gpus = '3'\n",
    "    feature = 'mel'\n",
    "    lr = 0.005\n",
    "    decay = 0.98\n",
    "    epoch = 300\n",
    "    batch = 8\n",
    "    channel = 2\n",
    "config = arg()\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.gpus\n",
    "strategy = tf.distribute.MirroredStrategy() # devices)\n",
    "path = './Music/6genres-100s'\n",
    "datapath, label = [], []\n",
    "classes = []\n",
    "sr = 22050\n",
    "with open('Music/6genres-100s/allgenres.mf') as f:\n",
    "    for i in f.readlines()[1:]:\n",
    "        tmp = i.split()\n",
    "        classes.append(tmp[1])\n",
    "        datapath.append(path + tmp[0][:-1])\n",
    "    label = classes\n",
    "    classes = list(set(classes))\n",
    "for i, j in enumerate(label):\n",
    "    label[i] = classes.index(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    raw = []\n",
    "    for i,j in enumerate(datapath):\n",
    "        _raw = librosa.load(j)\n",
    "        if sr != _raw[1]:\n",
    "            print(i, _raw[1])\n",
    "        raw.append(_raw[0][:660000])\n",
    "    return raw\n",
    "\n",
    "def preprocessing(rawdata, label, feature=config.feature):\n",
    "    x_index = 0\n",
    "    val_index = 0\n",
    "    data,val,y,val_y = [],[],[],[]\n",
    "    data = np.zeros((480,128,1290,3))\n",
    "    val = np.zeros((120,128,1290,3))\n",
    "    y = np.zeros((480,len(classes)))\n",
    "    val_y = np.zeros((120,len(classes)))\n",
    "    for i, raw in enumerate(tqdm(rawdata)):\n",
    "        _data = None\n",
    "        if feature == 'mel':\n",
    "#             gen = librosa.feature.melspectrogram(raw)\n",
    "            y_harmonic, y_percussive = librosa.effects.hpss(raw)\n",
    "            S_harmonic = librosa.feature.melspectrogram(y_harmonic)\n",
    "            S_percussive = librosa.feature.melspectrogram(y_percussive)\n",
    "#             log_o = librosa.power_to_db(gen, ref=np.max)\n",
    "#             log_Sh = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "#             log_Sp = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "#             _data = np.concatenate([np.expand_dims(log_o,-1),np.expand_dims(log_Sh,-1),np.expand_dims(log_Sp,-1)],axis=-1)\n",
    "            log_Sh = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "            log_Sp = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "            _data = np.concatenate([np.expand_dims(log_Sh,-1),np.expand_dims(log_Sp,-1)],axis=-1)\n",
    "        elif feature == 'stft':\n",
    "            data.append(np.expand_dims(librosa.stft(raw), -1))\n",
    "        elif feature == 'mfcc':\n",
    "            data.append(np.expand_dims(librosa.feature.mfcc(raw), -1))\n",
    "        \n",
    "        if i % 100 < 80:\n",
    "            data[x_index] = _data\n",
    "            y[x_index] = tf.one_hot(label[i], len(classes)).numpy()\n",
    "            x_index += 1\n",
    "        else:\n",
    "            val[val_index] = _data\n",
    "            val_y[val_index] = tf.one_hot(label[i], len(classes)).numpy()\n",
    "            val_index += 1\n",
    "    return (data, val, y, val_y)\n",
    "raw = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [24:38<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "x_2, x_val_2, _, _ = preprocessing(raw, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(x_2,open(datapath + '/x_mel_2.pickle','wb'))\n",
    "# pickle.dump(x_val_2,open(datapath + '/val_x_mel_2.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/root/class'\n",
    "if config.channel == 2:\n",
    "    x= pickle.load(open(datapath + '/x_mel_2.pickle','rb'))\n",
    "    val_x= pickle.load(open(datapath + '/val_x_mel_2.pickle', 'rb'))\n",
    "elif config.channel == 3:\n",
    "    x= pickle.load(open(datapath + '/x_mel.pickle','rb'))\n",
    "    val_x= pickle.load(open(datapath + '/val_x_mel.pickle', 'rb'))\n",
    "y= pickle.load(open(datapath + '/y.pickle', 'rb'))\n",
    "val_y= pickle.load(open(datapath + '/val_y.pickle', 'rb'))\n",
    "assert (len(y) == len(x)) and (len(val_x) == len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(len(x)).batch(config.batch).prefetch(AUTOTUNE)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).shuffle(len(val_x)).batch(config.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (x[0].shape[0], x[0].shape[1], x[0].shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(inputs):\n",
    "    x_1 = BatchNormalization()(inputs)\n",
    "    x_1 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_1)\n",
    "    \n",
    "    x_2 = BatchNormalization()(inputs)\n",
    "    x_2 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_2)\n",
    "    x_2 = BatchNormalization()(x_2)\n",
    "    x_2 = Conv2D(32,(3,3),strides=1,padding='same', activation='relu')(x_2)\n",
    "    \n",
    "    x_3 = BatchNormalization()(inputs)\n",
    "    x_3 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_3)\n",
    "    x_3 = BatchNormalization()(x_3)\n",
    "    x_3 = Conv2D(32,(5,5),strides=1,padding='same', activation='relu')(x_3)\n",
    "    \n",
    "    x_4 = MaxPool2D((3,3), strides=1, padding='same')(inputs)\n",
    "    x_4 = BatchNormalization()(x_4)\n",
    "    x_4 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_4)\n",
    "    \n",
    "    x_5 = BatchNormalization()(inputs)\n",
    "    x_5 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_5)\n",
    "    x_5 = BatchNormalization()(x_5)\n",
    "    x_5 = Conv2D(32,(7,7),strides=1,padding='same', activation='relu')(x_5)\n",
    "    \n",
    "    x_6 = AveragePooling2D((3,3), strides=1, padding='same')(inputs)\n",
    "    x_6 = BatchNormalization()(x_6)\n",
    "    x_6 = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x_6)\n",
    "    \n",
    "    return Concatenate()([inputs,x_1,x_2,x_3,x_4,x_5,x_6])\n",
    "\n",
    "def build_model():\n",
    "    model_input = Input(shape=shape) # shape 으로 변경\n",
    "    x = tf.transpose(model_input, [0,2,1,3])\n",
    "    x = Conv2D(32,(3,3),strides=1,padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D((4,1))(x)\n",
    "    \n",
    "    x_1 = inception_block(x)\n",
    "    x_2 = inception_block(Concatenate()([x,x_1]))\n",
    "    x_3 = inception_block(Concatenate()([x,x_1,x_2]))\n",
    "    \n",
    "    x = BatchNormalization()(x_3)\n",
    "    x = Conv2D(32,(1,1),strides=1,padding='same', activation='relu')(x)\n",
    "    x = AveragePooling2D((2,2), strides=2)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    out = Dense(len(classes), activation='softmax')(x)\n",
    "    return Model(inputs=model_input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model()\n",
    "# model.summary()\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#                                         config.lr,\n",
    "#                                         decay_steps=config.epoch,\n",
    "#                                         decay_rate=config.decay,\n",
    "#                                         staircase=True)\n",
    "factor = 0.7\n",
    "learning_rate = 0.01\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=factor, patience=3, verbose=0, mode='auto',\n",
    ")\n",
    "optimizers = Adam(learning_rate=learning_rate)\n",
    "# optimizers = SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(optimizer=optimizers,\n",
    "                      loss=tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics=['acc', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model_checkpoint/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=0, save_weights_only=True,\n",
    "    # 다섯 번째 에포크마다 가중치를 저장합니다\n",
    "    save_freq='epoch',\n",
    "#     save_best_only=True)\n",
    ")\n",
    "callbacks = [\n",
    "    cp_callback,\n",
    "    lr,\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          patience=25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 60 steps, validate for 15 steps\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 39s 642ms/step - loss: 1.1353 - acc: 0.5500 - Precision: 0.7309 - Recall: 0.3396 - val_loss: 5.7246 - val_acc: 0.1667 - val_Precision: 0.1667 - val_Recall: 0.1667\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 33s 558ms/step - loss: 0.9497 - acc: 0.6354 - Precision: 0.8125 - Recall: 0.4333 - val_loss: 2.2805 - val_acc: 0.2917 - val_Precision: 0.3605 - val_Recall: 0.2583\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.8760 - acc: 0.6875 - Precision: 0.8097 - Recall: 0.5229 - val_loss: 3.2483 - val_acc: 0.2750 - val_Precision: 0.2797 - val_Recall: 0.2750\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 34s 563ms/step - loss: 0.8687 - acc: 0.6938 - Precision: 0.8167 - Recall: 0.5104 - val_loss: 2.3727 - val_acc: 0.3333 - val_Precision: 0.3763 - val_Recall: 0.2917\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 33s 544ms/step - loss: 0.7192 - acc: 0.7333 - Precision: 0.8287 - Recall: 0.6250 - val_loss: 2.6601 - val_acc: 0.3167 - val_Precision: 0.3365 - val_Recall: 0.2917\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 33s 553ms/step - loss: 0.6148 - acc: 0.7937 - Precision: 0.8733 - Recall: 0.6750 - val_loss: 1.8689 - val_acc: 0.5250 - val_Precision: 0.5769 - val_Recall: 0.5000\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.5757 - acc: 0.8146 - Precision: 0.8804 - Recall: 0.7208 - val_loss: 1.9898 - val_acc: 0.3750 - val_Precision: 0.4286 - val_Recall: 0.3500\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 33s 545ms/step - loss: 0.5614 - acc: 0.8250 - Precision: 0.8647 - Recall: 0.7188 - val_loss: 1.3932 - val_acc: 0.5333 - val_Precision: 0.6517 - val_Recall: 0.4833\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.6029 - acc: 0.7875 - Precision: 0.8828 - Recall: 0.7063 - val_loss: 6.2400 - val_acc: 0.1750 - val_Precision: 0.1810 - val_Recall: 0.1750\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 32s 540ms/step - loss: 0.5135 - acc: 0.8292 - Precision: 0.8811 - Recall: 0.7563 - val_loss: 1.5597 - val_acc: 0.6250 - val_Precision: 0.6538 - val_Recall: 0.5667\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.5551 - acc: 0.8125 - Precision: 0.8665 - Recall: 0.7437 - val_loss: 1.4719 - val_acc: 0.4833 - val_Precision: 0.4821 - val_Recall: 0.4500\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 33s 555ms/step - loss: 0.4526 - acc: 0.8208 - Precision: 0.8979 - Recall: 0.7875 - val_loss: 1.4711 - val_acc: 0.5583 - val_Precision: 0.5575 - val_Recall: 0.5250\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 33s 552ms/step - loss: 0.4510 - acc: 0.8521 - Precision: 0.8884 - Recall: 0.7958 - val_loss: 6.9953 - val_acc: 0.2167 - val_Precision: 0.2101 - val_Recall: 0.2083\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 33s 553ms/step - loss: 0.4630 - acc: 0.8646 - Precision: 0.8850 - Recall: 0.7854 - val_loss: 1.4422 - val_acc: 0.5750 - val_Precision: 0.5926 - val_Recall: 0.5333\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.3953 - acc: 0.8771 - Precision: 0.9227 - Recall: 0.8208 - val_loss: 0.6955 - val_acc: 0.7333 - val_Precision: 0.7642 - val_Recall: 0.6750\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.4244 - acc: 0.8625 - Precision: 0.9149 - Recall: 0.8062 - val_loss: 1.0743 - val_acc: 0.6000 - val_Precision: 0.6195 - val_Recall: 0.5833\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 33s 549ms/step - loss: 0.4205 - acc: 0.8604 - Precision: 0.9097 - Recall: 0.8188 - val_loss: 0.5174 - val_acc: 0.8250 - val_Precision: 0.8598 - val_Recall: 0.7667\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 33s 549ms/step - loss: 0.3844 - acc: 0.8875 - Precision: 0.9234 - Recall: 0.8292 - val_loss: 0.8527 - val_acc: 0.6333 - val_Precision: 0.6697 - val_Recall: 0.6083\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 33s 543ms/step - loss: 0.4080 - acc: 0.8833 - Precision: 0.9215 - Recall: 0.8313 - val_loss: 1.7392 - val_acc: 0.4333 - val_Precision: 0.4615 - val_Recall: 0.4000\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 33s 543ms/step - loss: 0.3606 - acc: 0.8813 - Precision: 0.9226 - Recall: 0.8438 - val_loss: 1.3494 - val_acc: 0.6333 - val_Precision: 0.6325 - val_Recall: 0.6167\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 32s 541ms/step - loss: 0.3433 - acc: 0.8938 - Precision: 0.9253 - Recall: 0.8521 - val_loss: 0.4866 - val_acc: 0.8167 - val_Precision: 0.8627 - val_Recall: 0.7333\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.3529 - acc: 0.9062 - Precision: 0.9255 - Recall: 0.8542 - val_loss: 0.4604 - val_acc: 0.8083 - val_Precision: 0.8611 - val_Recall: 0.7750\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 32s 535ms/step - loss: 0.3279 - acc: 0.9021 - Precision: 0.9265 - Recall: 0.8667 - val_loss: 1.0282 - val_acc: 0.6667 - val_Precision: 0.6810 - val_Recall: 0.6583\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 32s 539ms/step - loss: 0.3005 - acc: 0.9187 - Precision: 0.9441 - Recall: 0.8792 - val_loss: 0.2731 - val_acc: 0.9250 - val_Precision: 0.9381 - val_Recall: 0.8833\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 33s 551ms/step - loss: 0.2933 - acc: 0.9042 - Precision: 0.9329 - Recall: 0.8687 - val_loss: 1.7598 - val_acc: 0.5083 - val_Precision: 0.5043 - val_Recall: 0.4917\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 32s 542ms/step - loss: 0.3248 - acc: 0.9042 - Precision: 0.9336 - Recall: 0.8792 - val_loss: 0.6758 - val_acc: 0.7500 - val_Precision: 0.8235 - val_Recall: 0.7000\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 33s 554ms/step - loss: 0.2897 - acc: 0.9271 - Precision: 0.9573 - Recall: 0.8875 - val_loss: 0.4474 - val_acc: 0.8250 - val_Precision: 0.8624 - val_Recall: 0.7833\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.2866 - acc: 0.9187 - Precision: 0.9405 - Recall: 0.8896 - val_loss: 0.2607 - val_acc: 0.9333 - val_Precision: 0.9474 - val_Recall: 0.9000\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 32s 541ms/step - loss: 0.3188 - acc: 0.8813 - Precision: 0.9229 - Recall: 0.8479 - val_loss: 0.5352 - val_acc: 0.8083 - val_Precision: 0.8273 - val_Recall: 0.7583\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.2785 - acc: 0.9229 - Precision: 0.9470 - Recall: 0.8938 - val_loss: 0.2521 - val_acc: 0.9417 - val_Precision: 0.9478 - val_Recall: 0.9083\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 32s 535ms/step - loss: 0.2926 - acc: 0.9146 - Precision: 0.9512 - Recall: 0.8938 - val_loss: 0.2958 - val_acc: 0.9250 - val_Precision: 0.9244 - val_Recall: 0.9167\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 33s 543ms/step - loss: 0.2742 - acc: 0.9167 - Precision: 0.9425 - Recall: 0.8875 - val_loss: 0.8437 - val_acc: 0.6667 - val_Precision: 0.7170 - val_Recall: 0.6333\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 33s 542ms/step - loss: 0.2755 - acc: 0.9208 - Precision: 0.9448 - Recall: 0.8917 - val_loss: 0.6281 - val_acc: 0.8000 - val_Precision: 0.8447 - val_Recall: 0.7250\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 33s 551ms/step - loss: 0.2387 - acc: 0.9354 - Precision: 0.9482 - Recall: 0.9146 - val_loss: 0.3652 - val_acc: 0.8417 - val_Precision: 0.8909 - val_Recall: 0.8167\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 33s 545ms/step - loss: 0.2006 - acc: 0.9438 - Precision: 0.9613 - Recall: 0.9312 - val_loss: 0.5353 - val_acc: 0.8083 - val_Precision: 0.8505 - val_Recall: 0.7583\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 33s 542ms/step - loss: 0.2331 - acc: 0.9396 - Precision: 0.9560 - Recall: 0.9062 - val_loss: 0.2386 - val_acc: 0.9250 - val_Precision: 0.9328 - val_Recall: 0.9250\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 33s 542ms/step - loss: 0.2262 - acc: 0.9312 - Precision: 0.9562 - Recall: 0.9104 - val_loss: 0.3259 - val_acc: 0.8917 - val_Precision: 0.8870 - val_Recall: 0.8500\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 32s 537ms/step - loss: 0.2334 - acc: 0.9271 - Precision: 0.9436 - Recall: 0.9062 - val_loss: 0.3107 - val_acc: 0.8667 - val_Precision: 0.9115 - val_Recall: 0.8583\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 33s 554ms/step - loss: 0.2181 - acc: 0.9438 - Precision: 0.9606 - Recall: 0.9146 - val_loss: 0.3180 - val_acc: 0.8833 - val_Precision: 0.8879 - val_Recall: 0.8583\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.2032 - acc: 0.9479 - Precision: 0.9550 - Recall: 0.9292 - val_loss: 0.2610 - val_acc: 0.9167 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 33s 558ms/step - loss: 0.1983 - acc: 0.9563 - Precision: 0.9631 - Recall: 0.9250 - val_loss: 0.3151 - val_acc: 0.9000 - val_Precision: 0.9123 - val_Recall: 0.8667\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 32s 539ms/step - loss: 0.2120 - acc: 0.9542 - Precision: 0.9609 - Recall: 0.9208 - val_loss: 0.3846 - val_acc: 0.8500 - val_Precision: 0.8448 - val_Recall: 0.8167\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 33s 548ms/step - loss: 0.2365 - acc: 0.9417 - Precision: 0.9544 - Recall: 0.9167 - val_loss: 0.2618 - val_acc: 0.9000 - val_Precision: 0.9138 - val_Recall: 0.8833\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 32s 538ms/step - loss: 0.2013 - acc: 0.9479 - Precision: 0.9675 - Recall: 0.9312 - val_loss: 0.3880 - val_acc: 0.8750 - val_Precision: 0.9167 - val_Recall: 0.8250\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 32s 535ms/step - loss: 0.1790 - acc: 0.9542 - Precision: 0.9678 - Recall: 0.9396 - val_loss: 0.3501 - val_acc: 0.8917 - val_Precision: 0.9107 - val_Recall: 0.8500\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.1785 - acc: 0.9646 - Precision: 0.9683 - Recall: 0.9542 - val_loss: 0.2667 - val_acc: 0.9000 - val_Precision: 0.9060 - val_Recall: 0.8833\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 32s 538ms/step - loss: 0.1773 - acc: 0.9604 - Precision: 0.9742 - Recall: 0.9438 - val_loss: 0.2649 - val_acc: 0.9083 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 32s 538ms/step - loss: 0.1661 - acc: 0.9604 - Precision: 0.9680 - Recall: 0.9458 - val_loss: 0.3070 - val_acc: 0.8833 - val_Precision: 0.8814 - val_Recall: 0.8667\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 32s 539ms/step - loss: 0.2158 - acc: 0.9458 - Precision: 0.9611 - Recall: 0.9271 - val_loss: 0.2335 - val_acc: 0.9333 - val_Precision: 0.9487 - val_Recall: 0.9250\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.1817 - acc: 0.9563 - Precision: 0.9698 - Recall: 0.9354 - val_loss: 0.2579 - val_acc: 0.9083 - val_Precision: 0.9304 - val_Recall: 0.8917\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 32s 541ms/step - loss: 0.1764 - acc: 0.9500 - Precision: 0.9740 - Recall: 0.9354 - val_loss: 0.3026 - val_acc: 0.8833 - val_Precision: 0.9052 - val_Recall: 0.8750\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 32s 538ms/step - loss: 0.1758 - acc: 0.9542 - Precision: 0.9618 - Recall: 0.9438 - val_loss: 0.2514 - val_acc: 0.9083 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 33s 546ms/step - loss: 0.1950 - acc: 0.9438 - Precision: 0.9630 - Recall: 0.9208 - val_loss: 0.2468 - val_acc: 0.9167 - val_Precision: 0.9322 - val_Recall: 0.9167\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.1924 - acc: 0.9479 - Precision: 0.9696 - Recall: 0.9292 - val_loss: 0.2715 - val_acc: 0.9167 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.1942 - acc: 0.9542 - Precision: 0.9695 - Recall: 0.9271 - val_loss: 0.2510 - val_acc: 0.9083 - val_Precision: 0.9160 - val_Recall: 0.9083\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 33s 552ms/step - loss: 0.1593 - acc: 0.9667 - Precision: 0.9725 - Recall: 0.9563 - val_loss: 0.2396 - val_acc: 0.9083 - val_Precision: 0.9068 - val_Recall: 0.8917\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 33s 548ms/step - loss: 0.1985 - acc: 0.9583 - Precision: 0.9700 - Recall: 0.9417 - val_loss: 0.2560 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 32s 540ms/step - loss: 0.1573 - acc: 0.9667 - Precision: 0.9764 - Recall: 0.9500 - val_loss: 0.2457 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.1439 - acc: 0.9708 - Precision: 0.9807 - Recall: 0.9542 - val_loss: 0.2545 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 32s 537ms/step - loss: 0.1599 - acc: 0.9667 - Precision: 0.9744 - Recall: 0.9521 - val_loss: 0.2510 - val_acc: 0.9167 - val_Precision: 0.9145 - val_Recall: 0.8917\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 32s 535ms/step - loss: 0.1604 - acc: 0.9646 - Precision: 0.9723 - Recall: 0.9521 - val_loss: 0.2496 - val_acc: 0.9167 - val_Precision: 0.9304 - val_Recall: 0.8917\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 32s 532ms/step - loss: 0.1487 - acc: 0.9708 - Precision: 0.9807 - Recall: 0.9542 - val_loss: 0.2471 - val_acc: 0.9250 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 32s 542ms/step - loss: 0.1613 - acc: 0.9729 - Precision: 0.9828 - Recall: 0.9542 - val_loss: 0.2411 - val_acc: 0.9167 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 33s 542ms/step - loss: 0.1912 - acc: 0.9563 - Precision: 0.9675 - Recall: 0.9312 - val_loss: 0.2436 - val_acc: 0.9250 - val_Precision: 0.9322 - val_Recall: 0.9167\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 33s 545ms/step - loss: 0.1517 - acc: 0.9729 - Precision: 0.9808 - Recall: 0.9583 - val_loss: 0.2450 - val_acc: 0.9250 - val_Precision: 0.9244 - val_Recall: 0.9167\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 33s 546ms/step - loss: 0.1677 - acc: 0.9625 - Precision: 0.9684 - Recall: 0.9563 - val_loss: 0.2306 - val_acc: 0.9250 - val_Precision: 0.9402 - val_Recall: 0.9167\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 32s 534ms/step - loss: 0.1846 - acc: 0.9646 - Precision: 0.9763 - Recall: 0.9438 - val_loss: 0.2413 - val_acc: 0.9167 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 32s 532ms/step - loss: 0.1704 - acc: 0.9604 - Precision: 0.9784 - Recall: 0.9438 - val_loss: 0.2402 - val_acc: 0.9250 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 33s 548ms/step - loss: 0.1516 - acc: 0.9750 - Precision: 0.9786 - Recall: 0.9542 - val_loss: 0.2413 - val_acc: 0.9167 - val_Precision: 0.9237 - val_Recall: 0.9083\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 34s 564ms/step - loss: 0.1574 - acc: 0.9604 - Precision: 0.9765 - Recall: 0.9521 - val_loss: 0.2392 - val_acc: 0.9167 - val_Precision: 0.9316 - val_Recall: 0.9083\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.1462 - acc: 0.9708 - Precision: 0.9829 - Recall: 0.9563 - val_loss: 0.2381 - val_acc: 0.9167 - val_Precision: 0.9316 - val_Recall: 0.9083\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 32s 538ms/step - loss: 0.1755 - acc: 0.9604 - Precision: 0.9761 - Recall: 0.9375 - val_loss: 0.2332 - val_acc: 0.9167 - val_Precision: 0.9322 - val_Recall: 0.9167\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 33s 552ms/step - loss: 0.1486 - acc: 0.9792 - Precision: 0.9893 - Recall: 0.9604 - val_loss: 0.2408 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 32s 535ms/step - loss: 0.1538 - acc: 0.9750 - Precision: 0.9828 - Recall: 0.9521 - val_loss: 0.2399 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 33s 553ms/step - loss: 0.1552 - acc: 0.9729 - Precision: 0.9787 - Recall: 0.9563 - val_loss: 0.2403 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/300\n",
      "60/60 [==============================] - 33s 544ms/step - loss: 0.1698 - acc: 0.9625 - Precision: 0.9744 - Recall: 0.9500 - val_loss: 0.2394 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 33s 542ms/step - loss: 0.1785 - acc: 0.9625 - Precision: 0.9742 - Recall: 0.9438 - val_loss: 0.2464 - val_acc: 0.9083 - val_Precision: 0.9145 - val_Recall: 0.8917\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 33s 556ms/step - loss: 0.1572 - acc: 0.9646 - Precision: 0.9701 - Recall: 0.9458 - val_loss: 0.2448 - val_acc: 0.9167 - val_Precision: 0.9310 - val_Recall: 0.9000\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 34s 559ms/step - loss: 0.1623 - acc: 0.9583 - Precision: 0.9827 - Recall: 0.9458 - val_loss: 0.2454 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 33s 548ms/step - loss: 0.1640 - acc: 0.9625 - Precision: 0.9743 - Recall: 0.9479 - val_loss: 0.2442 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.1401 - acc: 0.9667 - Precision: 0.9788 - Recall: 0.9604 - val_loss: 0.2440 - val_acc: 0.9083 - val_Precision: 0.9145 - val_Recall: 0.8917\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 34s 562ms/step - loss: 0.1567 - acc: 0.9708 - Precision: 0.9807 - Recall: 0.9542 - val_loss: 0.2422 - val_acc: 0.9083 - val_Precision: 0.9224 - val_Recall: 0.8917\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 33s 555ms/step - loss: 0.1703 - acc: 0.9563 - Precision: 0.9722 - Recall: 0.9458 - val_loss: 0.2418 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 33s 549ms/step - loss: 0.1558 - acc: 0.9667 - Precision: 0.9827 - Recall: 0.9458 - val_loss: 0.2409 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 33s 554ms/step - loss: 0.1576 - acc: 0.9708 - Precision: 0.9848 - Recall: 0.9458 - val_loss: 0.2412 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 34s 566ms/step - loss: 0.1379 - acc: 0.9750 - Precision: 0.9831 - Recall: 0.9667 - val_loss: 0.2413 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 33s 557ms/step - loss: 0.1480 - acc: 0.9646 - Precision: 0.9745 - Recall: 0.9563 - val_loss: 0.2408 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 33s 546ms/step - loss: 0.1446 - acc: 0.9708 - Precision: 0.9768 - Recall: 0.9646 - val_loss: 0.2419 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 33s 543ms/step - loss: 0.1579 - acc: 0.9583 - Precision: 0.9785 - Recall: 0.9500 - val_loss: 0.2418 - val_acc: 0.9167 - val_Precision: 0.9231 - val_Recall: 0.9000\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 34s 566ms/step - loss: 0.1724 - acc: 0.9583 - Precision: 0.9762 - Recall: 0.9417 - val_loss: 0.2413 - val_acc: 0.9167 - val_Precision: 0.9316 - val_Recall: 0.9083\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 33s 548ms/step - loss: 0.1531 - acc: 0.9688 - Precision: 0.9787 - Recall: 0.9563 - val_loss: 0.2410 - val_acc: 0.9167 - val_Precision: 0.9316 - val_Recall: 0.9083\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_dataset,epochs=config.epoch,validation_data=validation_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9367088385641422, epoch: 52\n"
     ]
    }
   ],
   "source": [
    "pre = hist.history['val_Precision']\n",
    "rec = hist.history['val_Recall']\n",
    "f1 = []\n",
    "for i, j in enumerate(pre):\n",
    "    f1.append(2 * pre[i] * rec[i] / (pre[i] + rec[i]))\n",
    "max_epoch = f1.index(np.nanmax(f1))+1\n",
    "print(f'f1_score: {np.nanmax(f1)}, epoch: {max_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82_adam_0.8,0.002,f10.9205021043027561.h5\n",
      "82_adam_0.8,0.004, f10.911392365275926.h5\n",
      "79_adam_0.75,0.001,f10.9198312696748169.h5\n",
      "82_adam_0.8,0.004,f10.911392365275926.h5\n",
      "78_adam_0.85,0.002,f10.911392365275926.h5\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir('./기록'):\n",
    "    if i[-3:] == '.h5':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52_adam_0.7,0.001,f10.9367088385641422,channel2\n"
     ]
    }
   ],
   "source": [
    "check_point = f'model_checkpoint/cp-00{max_epoch}.ckpt'\n",
    "model.load_weights(check_point)\n",
    "model.save(f'./기록/{max_epoch}_adam_{factor},{learning_rate},f1{np.max(f1)},channel{config.channel}.h5')\n",
    "print(f'{max_epoch}_adam_{factor},{learning_rate},f1{np.max(f1)},channel{config.channel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '52_adam_0.7,0.001,f10.9367088385641422,channel2' + '.h5'\n",
    "eval_model = tf.keras.models.load_model(f'./기록/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion table\n",
      "[[19.  0.  1.  0.  0.  0.]\n",
      " [ 0. 19.  0.  0.  1.  0.]\n",
      " [ 3.  0. 17.  0.  0.  0.]\n",
      " [ 0.  0.  1. 19.  0.  0.]\n",
      " [ 0.  0.  0.  0. 20.  0.]\n",
      " [ 2.  0.  0.  0.  0. 18.]]\n"
     ]
    }
   ],
   "source": [
    "confusion_table = np.reshape(np.zeros(6*6), (6,6))\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "for i,j in validation_dataset.unbatch().batch(1):\n",
    "    # j: real, answer: predict\n",
    "    answer = tf.argmax(eval_model.predict(i), axis=-1)\n",
    "    confusion_table[tf.argmax(j, axis=-1)[0]][answer.numpy()[0]] +=  1\n",
    "print('confusion table')\n",
    "print(confusion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is 0.9345212268832294\n"
     ]
    }
   ],
   "source": [
    "tp = np.zeros((6))\n",
    "fp = np.zeros_like(tp)\n",
    "fn = np.zeros_like(tp)\n",
    "\n",
    "for i,j in enumerate(confusion_table):\n",
    "    tp[i] = j[i] # confusion table에서 대각선\n",
    "    fn[i] = np.sum(j) - j[i] # confusion table에서 세로축\n",
    "    fp = np.add(fp, j) # confusion table에서 가로축\n",
    "    fp[i] -= j[i]\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(f'f1_score is {np.mean(f1_score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-141-cc9c12242ad7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-141-cc9c12242ad7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    eval_ model.evaluate(validation_dataset.unbatch().batch(1))\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eval_model.evaluate(validation_dataset.unbatch().batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
