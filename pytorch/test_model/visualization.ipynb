{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "from utils import *\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.ArgumentParser()\n",
    "args.add_argument('--gpus', type=str, default='0')\n",
    "args.add_argument('--batch', type=int, default=1)\n",
    "args.add_argument('--len', type=int, default=40)\n",
    "args.add_argument('--b', type=int, default=40)\n",
    "args.add_argument('--mode', type=str, default='sj_S')\n",
    "args.add_argument('--model', type=str, default='CombineAutoencoder')\n",
    "config = args.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8192\n",
    "WINDOW_SIZE = 500 # us\n",
    "data_length = config.len\n",
    "BATCH_SIZE = config.batch\n",
    "K, m = 8, 8\n",
    "ls = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSpath = '/home/skuser/'\n",
    "path = os.path.join(ABSpath, 'ai_model/pytorch/test_model')\n",
    "data_path = os.path.join(ABSpath,'data')\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "accel_raw_data = pickle.load(open(os.path.join(data_path,'stationary_accel_data.pickle'),'rb'))\n",
    "sound_raw_data = pickle.load(open(os.path.join(data_path,'stationary_sound_data.pickle'),'rb'))\n",
    "transfer_f = np.array(pickle.load(open(os.path.join(data_path,'transfer_f.pickle'),'rb')))\n",
    "transfer_f = torch.from_numpy(transfer_f).to(device)\n",
    "transfer_f.requires_grad = False\n",
    "\n",
    "# accel_data = dataSplit(accel_raw_data, takebeforetime=config.b, data_length=data_length, expand=True)\n",
    "# sound_data = dataSplit(sound_raw_data, takebeforetime=config.b, data_length=data_length, expand=False)\n",
    "# name = 'CombineAutoencoder_sj_S_40_40_adam_0.001_decay0.7071/*'\n",
    "# modelsavepath = sorted(glob(os.path.join(path, 'model_save/'+name)), key=lambda x: float(x.split('/')[-1].split('_')[-1]))[0]\n",
    "# model = getattr(models, config.model)(accel_data.shape[1] * accel_data.shape[2], sound_data.shape[1] * sound_data.shape[2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987136, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_raw_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 12 (delta 8), reused 12 (delta 8), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (12/12), done.\n",
      "From https://github.com/lsg1213/ai_model\n",
      " * branch            master     -> FETCH_HEAD\n",
      "   e96688e..ce3ba0c  master     -> origin/master\n",
      "Updating e96688e..ce3ba0c\n",
      "Fast-forward\n",
      " pytorch/test_model/train.py | 16 \u001b[32m++++++++\u001b[m\u001b[31m---\u001b[m\n",
      " pytorch/test_model/utils.py | 70 \u001b[32m++++++++++++++++++++++++\u001b[m\u001b[31m---------------------\u001b[m\n",
      " 2 files changed, 50 insertions(+), 36 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(modelsavepath)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accel_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([525107, 80, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([526082, 40, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "dataset = makeDataset(accel_data, sound_data, train=False)\n",
    "dataset_generator = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    res = torch.cat([conv_with_S(model(data.to(device).transpose(1,2)), transfer_f, device) for data, _ in dataset_generator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_with_S(model(dataset[0][0].unsqueeze(0).to(device).transpose(1,2)), transfer_f, device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21004280, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([i for i in res]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21043280, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([i for i in sound_data]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([525107, 40, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([526082, 40, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
